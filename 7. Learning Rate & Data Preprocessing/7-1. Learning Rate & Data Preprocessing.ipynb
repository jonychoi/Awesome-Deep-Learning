{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7-1: Tips\n",
    "\n",
    "**Jonathan Choi 2021**\n",
    "\n",
    "**[Deep Learning By Torch] End to End study scripts of Deep Learning by implementing code practice with Pytorch.**\n",
    "\n",
    "If you have an any issue, please PR below.\n",
    "\n",
    "[[Deep Learning By Torch] - Github @JonyChoi](https://github.com/jonychoi/Deep-Learning-By-Torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2384859d410>"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Datasets\n",
    "\n",
    "Trash Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1, 2, 1],\n",
    "                             [1, 3, 2],\n",
    "                             [1, 3, 4],\n",
    "                             [1, 5, 5],\n",
    "                             [1, 7, 5],\n",
    "                             [1, 2, 5],\n",
    "                             [1, 6, 6],\n",
    "                             [1, 7, 7]\n",
    "                            ])\n",
    "\n",
    "y_train = torch.LongTensor([2, 2, 2, 1, 1, 1, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_test = torch.FloatTensor([[2, 1, 1], [3, 1, 2], [3, 3, 4]])\n",
    " y_test = torch.LongTensor([2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 100\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        #prediction\n",
    "        pred = model(x_train)\n",
    "\n",
    "        #cost\n",
    "        cost = F.cross_entropy(pred, y_train)\n",
    "\n",
    "        #Reduce cost\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            print('Epoch {:d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Moment!\n",
    "\n",
    "**TORCH.TENSOR.MAX**\n",
    "\n",
    "Tensor.max(dim=None, keepdim=False) -> Tensor or (Tensor, Tensor)\n",
    "\n",
    "See ```torch.max()```\n",
    "\n",
    "**TORCH.MAX**\n",
    "\n",
    "torch.max(input) â†’ Tensor\n",
    "\n",
    "Returns the maximum value of all elements in the input tensor.\n",
    "\n",
    "torch.max(input, dim, keepdim=False, *, out=None) -> (Tensor, LongTensor)\n",
    "\n",
    "***Returns a namedtuple (values, indices) where values is the maximum value of each row of the input tensor in the given dimension dim.*** And indices is the index location of each maximum value found (argmax).\n",
    "\n",
    "If keepdim is True, the output tensors are of the same size as input except in the dimension dim where they are of size 1. Otherwise, dim is squeezed (see torch.squeeze()), resulting in the output tensors having 1 fewer dimension than input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, x_test, y_test):\n",
    "    pred = model(x_test)\n",
    "    predicted_class = pred.max(1)[1] # get the indicies of the maximum value of dimension 1 of the tensor\n",
    "    correct_count = (predicted_class == y_test).sum().item()\n",
    "    print(predicted_class , y_test)\n",
    "\n",
    "    #get accuracy\n",
    "    accuracy = correct_count / len(y_test) * 100\n",
    "\n",
    "    cost = F.cross_entropy(pred, y_test)\n",
    "    print('Accuracy: {}% Cost: {:.6f}'.format(accuracy, cost.item()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Cost: 2.203667\n",
      "Epoch 5/100 Cost: 1.089523\n",
      "Epoch 10/100 Cost: 1.048378\n",
      "Epoch 15/100 Cost: 1.014279\n",
      "Epoch 20/100 Cost: 0.983424\n",
      "Epoch 25/100 Cost: 0.955295\n",
      "Epoch 30/100 Cost: 0.929585\n",
      "Epoch 35/100 Cost: 0.906033\n",
      "Epoch 40/100 Cost: 0.884410\n",
      "Epoch 45/100 Cost: 0.864517\n",
      "Epoch 50/100 Cost: 0.846174\n",
      "Epoch 55/100 Cost: 0.829224\n",
      "Epoch 60/100 Cost: 0.813527\n",
      "Epoch 65/100 Cost: 0.798958\n",
      "Epoch 70/100 Cost: 0.785406\n",
      "Epoch 75/100 Cost: 0.772773\n",
      "Epoch 80/100 Cost: 0.760971\n",
      "Epoch 85/100 Cost: 0.749921\n",
      "Epoch 90/100 Cost: 0.739554\n",
      "Epoch 95/100 Cost: 0.729807\n",
      "Epoch 100/100 Cost: 0.720624\n"
     ]
    }
   ],
   "source": [
    "train(model,optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 2]) tensor([2, 2, 2])\n",
      "Accuracy: 100.0% Cost: 0.156923\n"
     ]
    }
   ],
   "source": [
    "test(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "$\\alpha$ of the Gradient Descent.\n",
    "\n",
    "learning rate is 0.1 at the code of ```optimizer = optim.SGD(model.parameters(), lr=0.1)```\n",
    "\n",
    "if the learning rate is too big, the cost is getting bigger as divergence (overshooting)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Cost: 1.280268\n",
      "Epoch 5/100 Cost: 1968197.625000\n",
      "Epoch 10/100 Cost: 1397263.250000\n",
      "Epoch 15/100 Cost: 685818.062500\n",
      "Epoch 20/100 Cost: 200090.937500\n",
      "Epoch 25/100 Cost: 307693.093750\n",
      "Epoch 30/100 Cost: 1676443.125000\n",
      "Epoch 35/100 Cost: 1478513.250000\n",
      "Epoch 40/100 Cost: 400614.625000\n",
      "Epoch 45/100 Cost: 759541.437500\n",
      "Epoch 50/100 Cost: 1282693.125000\n",
      "Epoch 55/100 Cost: 459963.750000\n",
      "Epoch 60/100 Cost: 660331.312500\n",
      "Epoch 65/100 Cost: 422489.625000\n",
      "Epoch 70/100 Cost: 594364.625000\n",
      "Epoch 75/100 Cost: 877507.750000\n",
      "Epoch 80/100 Cost: 505302.125000\n",
      "Epoch 85/100 Cost: 816148.062500\n",
      "Epoch 90/100 Cost: 861552.125000\n",
      "Epoch 95/100 Cost: 736444.875000\n",
      "Epoch 100/100 Cost: 896298.750000\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, if learning rate is too small, the cost is rarely reduced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Cost: 3.187324\n",
      "Epoch 5/100 Cost: 3.187324\n",
      "Epoch 10/100 Cost: 3.187324\n",
      "Epoch 15/100 Cost: 3.187324\n",
      "Epoch 20/100 Cost: 3.187324\n",
      "Epoch 25/100 Cost: 3.187324\n",
      "Epoch 30/100 Cost: 3.187324\n",
      "Epoch 35/100 Cost: 3.187324\n",
      "Epoch 40/100 Cost: 3.187324\n",
      "Epoch 45/100 Cost: 3.187324\n",
      "Epoch 50/100 Cost: 3.187324\n",
      "Epoch 55/100 Cost: 3.187324\n",
      "Epoch 60/100 Cost: 3.187324\n",
      "Epoch 65/100 Cost: 3.187324\n",
      "Epoch 70/100 Cost: 3.187324\n",
      "Epoch 75/100 Cost: 3.187324\n",
      "Epoch 80/100 Cost: 3.187324\n",
      "Epoch 85/100 Cost: 3.187324\n",
      "Epoch 90/100 Cost: 3.187324\n",
      "Epoch 95/100 Cost: 3.187324\n",
      "Epoch 100/100 Cost: 3.187324\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start at the appropriate number of the learning rate with adjusting the cost if overshooting as small, or if not reducing as large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SoftmaxClassifierModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/100 Cost: 1.341574\n",
      "Epoch 5/100 Cost: 1.102514\n",
      "Epoch 10/100 Cost: 1.043655\n",
      "Epoch 15/100 Cost: 0.994917\n",
      "Epoch 20/100 Cost: 0.954288\n",
      "Epoch 25/100 Cost: 0.920322\n",
      "Epoch 30/100 Cost: 0.891690\n",
      "Epoch 35/100 Cost: 0.867262\n",
      "Epoch 40/100 Cost: 0.846133\n",
      "Epoch 45/100 Cost: 0.827604\n",
      "Epoch 50/100 Cost: 0.811143\n",
      "Epoch 55/100 Cost: 0.796351\n",
      "Epoch 60/100 Cost: 0.782924\n",
      "Epoch 65/100 Cost: 0.770633\n",
      "Epoch 70/100 Cost: 0.759298\n",
      "Epoch 75/100 Cost: 0.748781\n",
      "Epoch 80/100 Cost: 0.738971\n",
      "Epoch 85/100 Cost: 0.729781\n",
      "Epoch 90/100 Cost: 0.721137\n",
      "Epoch 95/100 Cost: 0.712979\n",
      "Epoch 100/100 Cost: 0.705257\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "Let's make our data zero-centered and normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[73, 80, 75],\n",
    "                             [93, 88, 93],\n",
    "                             [89, 91, 90],\n",
    "                             [96, 98, 100],\n",
    "                             [73, 66, 70]])\n",
    "\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ x'_j = \\frac{x_j - \\mu_j}{\\sigma_j} $\n",
    "\n",
    "At here,the $\\sigma$ is standard deviation,and the $\\mu$ is the mean of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = x_train.mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = x_train.std(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_x_train = (x_train - mu) / sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0674, -0.3758, -0.8398],\n",
      "        [ 0.7418,  0.2778,  0.5863],\n",
      "        [ 0.3799,  0.5229,  0.3486],\n",
      "        [ 1.0132,  1.0948,  1.1409],\n",
      "        [-1.0674, -1.5197, -1.2360]])\n"
     ]
    }
   ],
   "source": [
    "print(norm_x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train with the normalized and zero-centered x_train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "   def __init__(self):\n",
    "       super().__init__()\n",
    "       self.linear = nn.Linear(3, 1)\n",
    "\n",
    "   def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF NOT DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "\n",
    "        #prediction\n",
    "        pred = model(x_train)\n",
    "\n",
    "        #cost\n",
    "        cost = F.mse_loss(pred, y_train)\n",
    "\n",
    "        #Reduce the cost\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:1d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 Cost: 57621.960938\n",
      "Epoch 1/20 Cost: 1115690762240.000000\n",
      "Epoch 2/20 Cost: 21603378185380036608.000000\n",
      "Epoch 3/20 Cost: 418311281336289389130547200.000000\n",
      "Epoch 4/20 Cost: 8099859627174812776678955834933248.000000\n",
      "Epoch 5/20 Cost: inf\n",
      "Epoch 6/20 Cost: inf\n",
      "Epoch 7/20 Cost: inf\n",
      "Epoch 8/20 Cost: inf\n",
      "Epoch 9/20 Cost: inf\n",
      "Epoch 10/20 Cost: inf\n",
      "Epoch 11/20 Cost: inf\n",
      "Epoch 12/20 Cost: nan\n",
      "Epoch 13/20 Cost: nan\n",
      "Epoch 14/20 Cost: nan\n",
      "Epoch 15/20 Cost: nan\n",
      "Epoch 16/20 Cost: nan\n",
      "Epoch 17/20 Cost: nan\n",
      "Epoch 18/20 Cost: nan\n",
      "Epoch 19/20 Cost: nan\n",
      "Epoch 20/20 Cost: nan\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IF DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 Cost: 29602.087891\n",
      "Epoch 1/20 Cost: 18798.478516\n",
      "Epoch 2/20 Cost: 11988.445312\n",
      "Epoch 3/20 Cost: 7660.372559\n",
      "Epoch 4/20 Cost: 4899.234375\n",
      "Epoch 5/20 Cost: 3134.669434\n",
      "Epoch 6/20 Cost: 2006.090454\n",
      "Epoch 7/20 Cost: 1284.011230\n",
      "Epoch 8/20 Cost: 821.937134\n",
      "Epoch 9/20 Cost: 526.222473\n",
      "Epoch 10/20 Cost: 336.965057\n",
      "Epoch 11/20 Cost: 215.836105\n",
      "Epoch 12/20 Cost: 138.308807\n",
      "Epoch 13/20 Cost: 88.686241\n",
      "Epoch 14/20 Cost: 56.922920\n",
      "Epoch 15/20 Cost: 36.589779\n",
      "Epoch 16/20 Cost: 23.571926\n",
      "Epoch 17/20 Cost: 15.236008\n",
      "Epoch 18/20 Cost: 9.896884\n",
      "Epoch 19/20 Cost: 6.475713\n",
      "Epoch 20/20 Cost: 4.282265\n"
     ]
    }
   ],
   "source": [
    "model = MultivariateLinearRegressionModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "train(model, optimizer, norm_x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "if the model is learned to well to the train data, it will not be the capacity to the test data.MultivariateLinearRegressionModel\n",
    "\n",
    "To prevent this, there are generally 3 ways.\n",
    "\n",
    "- 1. More train data.\n",
    "- 2. Less features\n",
    "- 3. **Regularization**\n",
    "\n",
    "Regularization: Let's not have too bit numbers in the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a moment!\n",
    "\n",
    "There are generally 3 ways of regularization.\n",
    "\n",
    "- 1. L1 Regularization\n",
    "- 2. L2 Regularization\n",
    "- 3. Dropout\n",
    "- 4. Early Stopping\n",
    "\n",
    "Here we are going to adopt the L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_regularization(model, optimizer, x_train, y_train):\n",
    "    nb_epochs = 20\n",
    "    for epoch in range(nb_epochs + 1):\n",
    "        \n",
    "        #prediction\n",
    "        pred = model(x_train)\n",
    "\n",
    "        #cost\n",
    "        cost = F.mse_loss(pred, y_train)\n",
    "\n",
    "        #L2 norm\n",
    "        l2_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "\n",
    "        cost += l2_reg\n",
    "\n",
    "        #Reduce the cost\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Epoch {:1d}/{} Cost: {:.6f}'.format(epoch, nb_epochs, cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/20 Cost: 29648.953125\n",
      "Epoch 1/20 Cost: 18888.650391\n",
      "Epoch 2/20 Cost: 12114.510742\n",
      "Epoch 3/20 Cost: 7807.997070\n",
      "Epoch 4/20 Cost: 5060.242188\n",
      "Epoch 5/20 Cost: 3304.121582\n",
      "Epoch 6/20 Cost: 2180.908936\n",
      "Epoch 7/20 Cost: 1462.253418\n",
      "Epoch 8/20 Cost: 1002.366821\n",
      "Epoch 9/20 Cost: 708.049927\n",
      "Epoch 10/20 Cost: 519.685913\n",
      "Epoch 11/20 Cost: 399.127502\n",
      "Epoch 12/20 Cost: 321.964600\n",
      "Epoch 13/20 Cost: 272.574799\n",
      "Epoch 14/20 Cost: 240.960114\n",
      "Epoch 15/20 Cost: 220.721405\n",
      "Epoch 16/20 Cost: 207.763870\n",
      "Epoch 17/20 Cost: 199.466415\n",
      "Epoch 18/20 Cost: 194.151688\n",
      "Epoch 19/20 Cost: 190.746063\n",
      "Epoch 20/20 Cost: 188.562561\n"
     ]
    }
   ],
   "source": [
    "train_with_regularization(model, optimizer, norm_x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
