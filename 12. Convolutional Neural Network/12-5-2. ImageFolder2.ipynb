{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.4.2: Image Folder 2\n",
    "\n",
    "**Jonathan Choi 2021**\n",
    "\n",
    "**[Deep Learning By Torch] End to End study scripts of Deep Learning by implementing code practice with Pytorch.**\n",
    "\n",
    "If you have an any issue, please PR below.\n",
    "\n",
    "[[Deep Learning By Torch] - Github @JonyChoi](https://github.com/jonychoi/Deep-Learning-By-Torch)\n",
    "\n",
    "Here, with the custom dataset that we defined, we will create the model to classify our label(here, cat and dog) with our custom CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define torchvision.transform property(To.Tensor()) to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root = 'catsanddogs/train_data/', transform=trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "training_epochs = 100\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = train_data, shuffle = True, batch_size = batch_size, drop_last = False, num_workers = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "## Only Adding 1 more Fully connected Layer makes accuaracy 15% up!!!!!!!\n",
    "\n",
    "50% -> 65%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(16 * 13 * 29, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.layer3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing\n",
    "net = CNN().to(device)\n",
    "test_input = (torch.Tensor(3, 3, 64, 128)).to(device)\n",
    "test_out = net(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 100, Cost: 2.372007\n",
      "Epoch 2 / 100, Cost: 0.725470\n",
      "Epoch 3 / 100, Cost: 0.675219\n",
      "Epoch 4 / 100, Cost: 0.677012\n",
      "Epoch 5 / 100, Cost: 0.645114\n",
      "Epoch 6 / 100, Cost: 0.635742\n",
      "Epoch 7 / 100, Cost: 0.622053\n",
      "Epoch 8 / 100, Cost: 0.615611\n",
      "Epoch 9 / 100, Cost: 0.557917\n",
      "Epoch 10 / 100, Cost: 0.605357\n",
      "Epoch 11 / 100, Cost: 0.529028\n",
      "Epoch 12 / 100, Cost: 0.557794\n",
      "Epoch 13 / 100, Cost: 0.470702\n",
      "Epoch 14 / 100, Cost: 0.524688\n",
      "Epoch 15 / 100, Cost: 0.565508\n",
      "Epoch 16 / 100, Cost: 0.477859\n",
      "Epoch 17 / 100, Cost: 0.399513\n",
      "Epoch 18 / 100, Cost: 0.454787\n",
      "Epoch 19 / 100, Cost: 0.426855\n",
      "Epoch 20 / 100, Cost: 0.361430\n",
      "Epoch 21 / 100, Cost: 0.316375\n",
      "Epoch 22 / 100, Cost: 0.412758\n",
      "Epoch 23 / 100, Cost: 0.357465\n",
      "Epoch 24 / 100, Cost: 0.370292\n",
      "Epoch 25 / 100, Cost: 0.263527\n",
      "Epoch 26 / 100, Cost: 0.257853\n",
      "Epoch 27 / 100, Cost: 0.182289\n",
      "Epoch 28 / 100, Cost: 0.216509\n",
      "Epoch 29 / 100, Cost: 0.237303\n",
      "Epoch 30 / 100, Cost: 0.233547\n",
      "Epoch 31 / 100, Cost: 0.300460\n",
      "Epoch 32 / 100, Cost: 0.167145\n",
      "Epoch 33 / 100, Cost: 0.151696\n",
      "Epoch 34 / 100, Cost: 0.138581\n",
      "Epoch 35 / 100, Cost: 0.192900\n",
      "Epoch 36 / 100, Cost: 0.210248\n",
      "Epoch 37 / 100, Cost: 0.099723\n",
      "Epoch 38 / 100, Cost: 0.088780\n",
      "Epoch 39 / 100, Cost: 0.112993\n",
      "Epoch 40 / 100, Cost: 0.179528\n",
      "Epoch 41 / 100, Cost: 0.125220\n",
      "Epoch 42 / 100, Cost: 0.077691\n",
      "Epoch 43 / 100, Cost: 0.084658\n",
      "Epoch 44 / 100, Cost: 0.064562\n",
      "Epoch 45 / 100, Cost: 0.065298\n",
      "Epoch 46 / 100, Cost: 0.034124\n",
      "Epoch 47 / 100, Cost: 0.100494\n",
      "Epoch 48 / 100, Cost: 0.117106\n",
      "Epoch 49 / 100, Cost: 0.295237\n",
      "Epoch 50 / 100, Cost: 0.069935\n",
      "Epoch 51 / 100, Cost: 0.042277\n",
      "Epoch 52 / 100, Cost: 0.046221\n",
      "Epoch 53 / 100, Cost: 0.069382\n",
      "Epoch 54 / 100, Cost: 0.025757\n",
      "Epoch 55 / 100, Cost: 0.021963\n",
      "Epoch 56 / 100, Cost: 0.137718\n",
      "Epoch 57 / 100, Cost: 0.073334\n",
      "Epoch 58 / 100, Cost: 0.022832\n",
      "Epoch 59 / 100, Cost: 0.014641\n",
      "Epoch 60 / 100, Cost: 0.092835\n",
      "Epoch 61 / 100, Cost: 0.402841\n",
      "Epoch 62 / 100, Cost: 0.041290\n",
      "Epoch 63 / 100, Cost: 0.081675\n",
      "Epoch 64 / 100, Cost: 0.131654\n",
      "Epoch 65 / 100, Cost: 0.067226\n",
      "Epoch 66 / 100, Cost: 0.044631\n",
      "Epoch 67 / 100, Cost: 0.098849\n",
      "Epoch 68 / 100, Cost: 0.077069\n",
      "Epoch 69 / 100, Cost: 0.062894\n",
      "Epoch 70 / 100, Cost: 0.011615\n",
      "Epoch 71 / 100, Cost: 0.002247\n",
      "Epoch 72 / 100, Cost: 0.005159\n",
      "Epoch 73 / 100, Cost: 0.004192\n",
      "Epoch 74 / 100, Cost: 0.000912\n",
      "Epoch 75 / 100, Cost: 0.000873\n",
      "Epoch 76 / 100, Cost: 0.000507\n",
      "Epoch 77 / 100, Cost: 0.000335\n",
      "Epoch 78 / 100, Cost: 0.000669\n",
      "Epoch 79 / 100, Cost: 0.002179\n",
      "Epoch 80 / 100, Cost: 0.010161\n",
      "Epoch 81 / 100, Cost: 0.085492\n",
      "Epoch 82 / 100, Cost: 0.060463\n",
      "Epoch 83 / 100, Cost: 0.028673\n",
      "Epoch 84 / 100, Cost: 0.083615\n",
      "Epoch 85 / 100, Cost: 0.080030\n",
      "Epoch 86 / 100, Cost: 0.061036\n",
      "Epoch 87 / 100, Cost: 0.146444\n",
      "Epoch 88 / 100, Cost: 0.094049\n",
      "Epoch 89 / 100, Cost: 0.138851\n",
      "Epoch 90 / 100, Cost: 0.249103\n",
      "Epoch 91 / 100, Cost: 0.090855\n",
      "Epoch 92 / 100, Cost: 0.050005\n",
      "Epoch 93 / 100, Cost: 0.023777\n",
      "Epoch 94 / 100, Cost: 0.013617\n",
      "Epoch 95 / 100, Cost: 0.023078\n",
      "Epoch 96 / 100, Cost: 0.009194\n",
      "Epoch 97 / 100, Cost: 0.006714\n",
      "Epoch 98 / 100, Cost: 0.004449\n",
      "Epoch 99 / 100, Cost: 0.000315\n",
      "Epoch 100 / 100, Cost: 0.000003\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        #prediction\n",
    "        pred = net(X)\n",
    "\n",
    "        #cost\n",
    "        cost = F.cross_entropy(pred, Y)\n",
    "\n",
    "        #Reduce the cost\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost\n",
    "    \n",
    "    avg_cost = avg_cost / total_batch\n",
    "\n",
    "    print('Epoch {} / {}, Cost: {:.6f}'.format(epoch+1, training_epochs, avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./models/catsanddogs_cnn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net.load_state_dict(torch.load('./models/catsanddogs_cnn.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "tensor([ 0.3255,  0.2246,  0.1672,  0.0831, -0.3185], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n",
      "tensor([ 0.3255,  0.2246,  0.1672,  0.0831, -0.3185], device='cuda:0',\n",
      "       grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]]], device='cuda:0')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net.layer1[0])\n",
    "print(new_net.layer1[0])\n",
    "\n",
    "print(net.layer1[0].weight[0][0][0])\n",
    "print(new_net.layer1[0].weight[0][0][0])\n",
    "net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define torchvision.transforms property (To.Tensor and Resize) to Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose([\n",
    "    transforms.Resize((64, 128)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_data = torchvision.datasets.ImageFolder(root = './catsanddogs/test_data', transform = trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = torch.utils.data.DataLoader(dataset = test_data, batch_size = len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.650000\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for X, Y in test_set:\n",
    "\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        prediction = new_net(X)\n",
    "\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "\n",
    "    print('Accuracy: {:.6f}'.format(accuracy.item()))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
