{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 10.3.2 MNIST-CNN with Visdom\n",
    "\n",
    "**Jonathan Choi 2021**\n",
    "\n",
    "**[Deep Learning By Torch] End to End study scripts of Deep Learning by implementing code practice with Pytorch.**\n",
    "\n",
    "If you have an any issue, please PR below.\n",
    "\n",
    "[[Deep Learning By Torch] - Github @JonyChoi](https://github.com/jonychoi/Deep-Learning-By-Torch)\n",
    "\n",
    "Here we will create the CNN model to classify the MNIST with visualizing tool of Visdom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init as init\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import visdom\n",
    "\n",
    "vis = visdom.Visdom()\n",
    "vis.close(env = \"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define loss_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, num):\n",
    "    #num, loss_value are Tensor\n",
    "    vis.line(X = num, Y=loss_value, win=loss_plot, update='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = datasets.MNIST(download = True,\n",
    "                             train = True,\n",
    "                             transform = transforms.ToTensor(),\n",
    "                             root = 'MNIST_data/')\n",
    "mnist_test = datasets.MNIST(root = 'MNIST_data/',\n",
    "                            train = False,\n",
    "                            download = True,\n",
    "                            transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset = mnist_train, shuffle = True, drop_last = True, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(3 * 3 * 128, 625)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(625, 10, bias = True)\n",
    "        torch.nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        torch.nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        #print(out.shape) torch.Size([1, 128, 3, 3])\n",
    "        out = out.view(out.size(0), -1)\n",
    "        #print(out.shape) torch.Size([1, 1152])\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\buddhalight\\envs\\buddhalight\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "value = torch.Tensor(1,1,28,28).to(device)\n",
    "print(model(value).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_plt = vis.line(Y = torch.Tensor(1).zero_(), opts = dict(title = 'loss_tracker', legend=['loss'], showlegend = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with loss_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 / 15, Cost: 0.116303\n",
      "Epoch: 2 / 15, Cost: 0.040117\n",
      "Epoch: 3 / 15, Cost: 0.028779\n",
      "Epoch: 4 / 15, Cost: 0.021760\n",
      "Epoch: 5 / 15, Cost: 0.017429\n",
      "Epoch: 6 / 15, Cost: 0.014483\n",
      "Epoch: 7 / 15, Cost: 0.012259\n",
      "Epoch: 8 / 15, Cost: 0.010881\n",
      "Epoch: 9 / 15, Cost: 0.010224\n",
      "Epoch: 10 / 15, Cost: 0.007701\n",
      "Epoch: 11 / 15, Cost: 0.009009\n",
      "Epoch: 12 / 15, Cost: 0.006754\n",
      "Epoch: 13 / 15, Cost: 0.007524\n",
      "Epoch: 14 / 15, Cost: 0.007479\n",
      "Epoch: 15 / 15, Cost: 0.005707\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        #prediction\n",
    "        pred = model(X)\n",
    "\n",
    "        #cost\n",
    "        cost = F.cross_entropy(pred, Y)\n",
    "\n",
    "        #Reduce the cost\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost\n",
    "\n",
    "    avg_cost = avg_cost / total_batch\n",
    "\n",
    "    print('Epoch: {} / {}, Cost: {:.6f}'.format(epoch+1, training_epochs, avg_cost))\n",
    "    loss_tracker(loss_plt, torch.Tensor([avg_cost]), torch.Tensor([epoch]))\n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./imgs/plot1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 28, 28])\n",
      "torch.uint8\n",
      "torch.Size([10000, 1, 28, 28])\n",
      "torch.float32\n",
      "torch.Size([1, 1, 28, 28])\n",
      "Accuracy: 0.949599981\n",
      "Prediction: 0, Label: 0\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(mnist_test.data.shape)\n",
    "    print(mnist_test.data[0].dtype)\n",
    "    X_test = mnist_test.data.view(len(mnist_test), 1, 28, 28).float().to(device)#if not .float() error : RuntimeError: Input type (torch.cuda.ByteTensor) and weight type (torch.cuda.FloatTensor) should be the same\n",
    "    print(X_test.shape)\n",
    "    print(X_test[0].dtype)\n",
    "    Y_test = mnist_test.targets.to(device)\n",
    "\n",
    "    pred = model(X_test).to(device)\n",
    "    correct_prediction = (torch.argmax(pred, 1) == Y_test)\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "\n",
    "    r = random.randint(0, len(X_test.data) - 1)\n",
    "    X_single_prediction = X_test[r:r+1]\n",
    "    Y_single_prediction = Y_test[r:r+1]\n",
    "    print(X_single_prediction.shape) # if [r] => torch.size([1, 28, 28]) # if [r:r+1] => torch.size([1,1,28,28])\n",
    "    \n",
    "    print('Accuracy: {:.9f}'.format(accuracy.item()))\n",
    "    print('Prediction: {}, Label: {}'.format(torch.argmax(model(X_single_prediction)), Y_single_prediction.item()))\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
