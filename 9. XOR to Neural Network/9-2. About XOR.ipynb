{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8-1: About XOR\n",
    "\n",
    "**Jonathan Choi 2021**\n",
    "\n",
    "**[Deep Learning By Torch] End to End study scripts of Deep Learning by implementing code practice with Pytorch.**\n",
    "\n",
    "If you have an any issue, please PR below.\n",
    "\n",
    "[[Deep Learning By Torch] - Github @JonyChoi](https://github.com/jonychoi/Deep-Learning-By-Torch)\n",
    "\n",
    "Here, the 'About XOR' will gonna handle about the XOR problem, that is proved \"1 Layer\" perceptron cannot solve the problem. We are gonna define the XOR Problem as a torch.tensor, and will create the 1 linear layer(~=1 layer perceptron) to sure about whether really the 1 layer perceptron cannot solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the XOR Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 1 Layer Perceptron Model to solve the XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nn layers\n",
    "linear = torch.nn.Linear(2, 1)\n",
    "sigmoid = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = torch.nn.Sequential(linear, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cost & optimizer\n",
    "criterion = torch.nn.BCELoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the 1-Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 1900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 2900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 3900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 4900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 5900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 6900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 7900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 8900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9100/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9200/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9300/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9400/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9500/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9600/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9700/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9800/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 9900/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n",
      "Epoch: 10000/1000 \n",
      " Prediction: [0.62248445 0.62245303 0.6224656  0.6224342 ] Cost: 0.693147\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "\n",
    "    #cost\n",
    "    cost = criterion(pred, Y)\n",
    "\n",
    "    #Reduce cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        result = torch.sigmoid(pred).squeeze().detach().cpu().numpy()\n",
    "        print('Epoch: {:2d}/1000 \\n Prediction: {} Cost: {:.6f}'.format(step, result, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As the results below, we can see the 1 layer perceptron(1 linear layer) **cannot solve the XOR problem.**(The maximum accruacy is 0.5, this means no matter how hard train it, it can only correct the half. - the property of the linear)\n",
    "\n",
    "This means that the 1 layer perceptron cannot solve the ***non-linear** problem, that can only solve the ***Linear*** Problem.\n",
    "\n",
    "![](https://miro.medium.com/max/962/1*YzgdEbLiB17x3jB28gSAdw.png)\n",
    "\n",
    "https://towardsdatascience.com/the-magic-behind-the-perceptron-network-eaa461088367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypothesis:  [[0.500107  ]\n",
      " [0.49997312]\n",
      " [0.5000269 ]\n",
      " [0.49989298]] \n",
      " Correct:  [[1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]] \n",
      " Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "#Accuracy computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "    predicted = (pred > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\n Hypothesis: ', pred.detach().cpu().numpy(), '\\n Predicted: ', predicted.detach().cpu().numpy(), '\\n Accuracy: ', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High Level Implementation with ```nn.Module```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR_SingleLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XOR_SingleLayer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 1000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 2000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 3000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 4000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 5000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 6000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 7000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 8000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 9000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n",
      "Epoch: 10000 / 10000, Result: [0.6224185  0.62248766 0.6224309  0.6225001 ], Cost: 0.693147\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10001\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "\n",
    "    #cost\n",
    "    cost = F.binary_cross_entropy(pred, Y).to(device)\n",
    "\n",
    "    #Reduce the cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        result = torch.sigmoid(pred).squeeze().detach().cpu().numpy()\n",
    "        print('Epoch: {:2d} / 10000, Result: {}, Cost: {:.6f}'.format(epoch, result, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Hypothesis:  [[0.49982643]\n",
      " [0.5001209 ]\n",
      " [0.49987915]\n",
      " [0.5001736 ]] \n",
      " Predicted:  [[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]] \n",
      " Accuracy:  0.5\n"
     ]
    }
   ],
   "source": [
    "#Accuracy computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "    predicted = (pred > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "    print('\\n Hypothesis: ', pred.detach().cpu().numpy(), '\\n Predicted: ', predicted.detach().cpu().numpy(), '\\n Accuracy: ', accuracy.item())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
