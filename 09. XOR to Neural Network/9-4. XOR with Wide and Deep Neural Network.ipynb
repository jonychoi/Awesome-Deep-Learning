{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8-3: XOR with Wide and Deep Neural Network\n",
    "\n",
    "**Jonathan Choi 2021**\n",
    "\n",
    "**[Deep Learning By Torch] End to End study scripts of Deep Learning by implementing code practice with Pytorch.**\n",
    "\n",
    "If you have an any issue, please PR below.\n",
    "\n",
    "[[Deep Learning By Torch] - Github @JonyChoi](https://github.com/jonychoi/Deep-Learning-By-Torch)\n",
    "\n",
    "Here, we are going to learn about how the wide and deep neural network can change the process of learning and the reducing cost of XOR problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define XOR Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Wide and Deep Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn layers\n",
    "linear1 = nn.Linear(2, 10)\n",
    "linear2 = nn.Linear(10, 10)\n",
    "linear3 = nn.Linear(10, 10)\n",
    "linear4 = nn.Linear(10, 1)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    0/10000, Result: [0.6539865 0.6540312 0.6539376 0.6539956], Cost: 0.731973\n",
      "Epoch: 1000/10000, Result: [0.62243706 0.62250036 0.6224063  0.62246627], Cost: 0.693140\n",
      "Epoch: 2000/10000, Result: [0.62244695 0.6225462  0.6224133  0.6224938 ], Cost: 0.693107\n",
      "Epoch: 3000/10000, Result: [0.6224198  0.6225931  0.62239367 0.62253016], Cost: 0.693069\n",
      "Epoch: 4000/10000, Result: [0.62223357 0.6227078  0.62229025 0.6226171 ], Cost: 0.692835\n",
      "Epoch: 5000/10000, Result: [0.58411795 0.6377132  0.62946147 0.6384127 ], Cost: 0.615173\n",
      "Epoch: 6000/10000, Result: [0.50020653 0.7308674  0.7308163  0.5003069 ], Cost: 0.001065\n",
      "Epoch: 7000/10000, Result: [0.5000864  0.7309806  0.73095864 0.5001244 ], Cost: 0.000437\n",
      "Epoch: 8000/10000, Result: [0.5000536  0.7310111  0.73099756 0.500076  ], Cost: 0.000268\n",
      "Epoch: 9000/10000, Result: [0.5000386  0.7310245  0.7310147  0.50005406], Cost: 0.000192\n",
      "Epoch: 10000/10000, Result: [0.50003004 0.73103225 0.73102444 0.5000416 ], Cost: 0.000149\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "\n",
    "    #cost\n",
    "    cost = criterion(pred, Y)\n",
    "\n",
    "    #Reduce the cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        result = sigmoid(pred).squeeze().detach().cpu().numpy()\n",
    "        print('Epoch: {:4d}/10000, Result: {}, Cost: {:.6f}'.format(step, result, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[1.19966135e-04]\n",
      " [9.99865890e-01]\n",
      " [9.99826610e-01]\n",
      " [1.66115104e-04]], \n",
      "Predicted: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], \n",
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "    predicted = (pred > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean() *100\n",
    "    print('Prediction: {}, \\nPredicted: {}, \\nAccuracy: {}'.format(pred.detach().cpu().numpy(), predicted.detach().cpu().numpy(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Implementation with ```nn.Module```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR_Wide_Deep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.sq = nn.Sequential(\n",
    "            nn.Linear(2, 10),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(10, 10),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(10, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.sq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XOR_Wide_Deep().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/10000, result: [0.60209876 0.60213494 0.6020612  0.60210985], cost: 0.708109\n",
      "Epoch: 1000/10000, result: [0.6224386  0.6224769  0.62242305 0.6224517 ], cost: 0.693127\n",
      "Epoch: 2000/10000, result: [0.6224384  0.62247753 0.62241894 0.62245524], cost: 0.693141\n",
      "Epoch: 3000/10000, result: [0.62243104 0.6224865  0.6224224  0.6224708 ], cost: 0.693133\n",
      "Epoch: 4000/10000, result: [0.6224201  0.62248063 0.62240714 0.622475  ], cost: 0.693163\n",
      "Epoch: 5000/10000, result: [0.6224164 0.6225073 0.6224153 0.6224915], cost: 0.693116\n",
      "Epoch: 6000/10000, result: [0.6223871 0.6225118 0.6223942 0.622507 ], cost: 0.693122\n",
      "Epoch: 7000/10000, result: [0.6223548  0.62254095 0.62237835 0.6225446 ], cost: 0.693105\n",
      "Epoch: 8000/10000, result: [0.62221515 0.62258583 0.6223145  0.6226085 ], cost: 0.692985\n",
      "Epoch: 9000/10000, result: [0.6205708  0.62311643 0.62223154 0.62352747], cost: 0.690540\n",
      "Epoch: 10000/10000, result: [0.5002793  0.7306931  0.73068523 0.5004934 ], cost: 0.001713\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10001\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "\n",
    "    #cost\n",
    "    cost = F.binary_cross_entropy(pred, Y).to(device)\n",
    "\n",
    "    #Reduce cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        result = torch.sigmoid(pred).squeeze().detach().cpu().numpy()\n",
    "        print('Epoch: {:2d}/10000, result: {}, cost: {:.6f}'.format(epoch, result, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [[0.00111703]\n",
      " [0.99814284]\n",
      " [0.9980995 ]\n",
      " [0.00196971]], \n",
      "Predicted: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], \n",
      "Accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Accuracy computation\n",
    "# True if hypothesis > 0.5 else False\n",
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "    predicted = (pred > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean() *100\n",
    "    print('Prediction: {}, \\nPredicted: {}, \\nAccuracy: {}'.format(pred.detach().cpu().numpy(), predicted.detach().cpu().numpy(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
