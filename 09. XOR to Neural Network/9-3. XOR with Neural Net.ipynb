{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8-2: XOR with Nerual Net\n",
    "\n",
    "**Jonathan Choi 2021**\n",
    "\n",
    "**[Deep Learning By Torch] End to End study scripts of Deep Learning by implementing code practice with Pytorch.**\n",
    "\n",
    "If you have an any issue, please PR below.\n",
    "\n",
    "[[Deep Learning By Torch] - Github @JonyChoi](https://github.com/jonychoi/Deep-Learning-By-Torch)\n",
    "\n",
    "Here, we are going to learn about how the multi-layer perceptron can solve the XOR Problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the XOR Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
    "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Multi Layer Perceptron (Multi Linear Layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn Layers\n",
    "linear1 = nn.Linear(2, 2)\n",
    "linear2 = nn.Linear(2, 1)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "model = nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define cost & optimizer\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the multi layer perceptron(Neural Network)\n",
    "\n",
    "We can say multi layer(over 1 layer) perceptron with backpropagation as **'Neural Network'**.\n",
    "\n",
    "Actually, the MLP (Multi Layer Perceptron) is the subset of the DNN (Neural Network).\n",
    "\n",
    "About the DNN, NN, and MLP, please check additional writes at 08.0 - About the Neural Network.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10000, result: [0.6378827  0.63997304 0.6364925  0.63870925] cost: 0.702758\n",
      "Epoch:1000/10000, result: [0.6133584  0.5975663  0.67112035 0.6092756 ] cost: 0.618071\n",
      "Epoch:2000/10000, result: [0.5035969  0.72880906 0.7289416  0.5031296 ] cost: 0.012341\n",
      "Epoch:3000/10000, result: [0.50156736 0.7300963  0.73012793 0.5013755 ] cost: 0.005362\n",
      "Epoch:4000/10000, result: [0.50099635 0.730452   0.7304612  0.50087863] cost: 0.003411\n",
      "Epoch:5000/10000, result: [0.500729   0.7306182  0.73061895 0.50064355] cost: 0.002494\n",
      "Epoch:6000/10000, result: [0.5005743  0.73070943 0.73071426 0.500508  ] cost: 0.001966\n",
      "Epoch:7000/10000, result: [0.5004734  0.7307734  0.7307743  0.50041914] cost: 0.001618\n",
      "Epoch:8000/10000, result: [0.5004025  0.73081535 0.73081684 0.5003571 ] cost: 0.001377\n",
      "Epoch:9000/10000, result: [0.5003502  0.7308465  0.7308482  0.50031084] cost: 0.001199\n",
      "Epoch:10000/10000, result: [0.50030965 0.73087233 0.7308715  0.50027514] cost: 0.001060\n"
     ]
    }
   ],
   "source": [
    "for step in range(10001):\n",
    "\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "\n",
    "    #cost\n",
    "    cost = criterion(pred, Y)\n",
    "\n",
    "    #Reduce cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if step % 1000 == 0:\n",
    "        result = sigmoid(pred).squeeze().detach().cpu().numpy()\n",
    "        print('Epoch:{:2d}/10000, result: {} cost: {:.6f}'.format(step, result, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "As below, the prediction shows the multi layer perceptron solved the XOR problem.\n",
    "\n",
    "We can say this as ***non-linear*** function, that multi layering can act as non-linear function, otherwise the single layer perceptron can only be as ***linear*** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0.00123849 0.99905306 0.9990484  0.00110031] \n",
      "Predicted: [0. 1. 1. 0.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Accuracy computation\n",
    "#True if hypothesis > 0.5 else False\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(X)\n",
    "    predicted = (prediction > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "\n",
    "    print('Prediction: {} \\nPredicted: {}\\nAccuracy: {}'.format(prediction.squeeze().detach().cpu().numpy(), predicted.squeeze().detach().cpu().numpy(), accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-level Implementation with ```nn.Module```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR_MultiLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(2, 2)\n",
    "        self.linear2 = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return nn.Sequential(\n",
    "            linear1,\n",
    "            sigmoid,\n",
    "            linear2,\n",
    "            sigmoid\n",
    "        )(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XOR_MultiLayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a Moment!\n",
    "\n",
    "just writing as ```nn.Sigmoid(pred)``` makes an error of \"TypeError: __init__() takes 1 positional argument but 2 were given.\"\n",
    "\n",
    "=> You are using it as an instance method so you must include self as the first argument\n",
    "\n",
    "https://stackoverflow.com/questions/50275814/sigmoid-takes-1-positional-argument-but-2-were-given\n",
    "\n",
    "---\n",
    "\n",
    "So we should use torch.sigmoid if we want to apply the sigmoid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 1000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 2000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 3000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 4000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 5000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 6000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 7000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 8000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 9000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n",
      "Epoch: 10000/10000, result: [0.50030965 0.73087233 0.7308715  0.5002751 ], cost: 0.001060\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 10001\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "\n",
    "    #prediction\n",
    "    pred = model(X)\n",
    "\n",
    "    #cost function\n",
    "    cost = F.binary_cross_entropy(pred, Y)\n",
    "\n",
    "    #Reduce cost\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        result = torch.sigmoid(pred).squeeze().detach().cpu().numpy()\n",
    "        print('Epoch: {:2d}/10000, result: {}, cost: {:.6f}'.format(epoch, result, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0.00123849 0.99905306 0.9990484  0.00110031] \n",
      "Predicted: [0. 1. 1. 0.]\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "#Accuracy computation\n",
    "#True if hypothesis > 0.5 else False\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = model(X)\n",
    "    predicted = (prediction > 0.5).float()\n",
    "    accuracy = (predicted == Y).float().mean()\n",
    "\n",
    "    print('Prediction: {} \\nPredicted: {}\\nAccuracy: {}'.format(prediction.squeeze().detach().cpu().numpy(), predicted.squeeze().detach().cpu().numpy(), accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "38ed4d61829b01de31b0fe0651719916120d9f7e023a62cbbfea93b7d24a50a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('buddhalight': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
